{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be4840-b77d-4090-aeea-038e1abddde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain openai ragas arxiv pymupdf\n",
    "!pip install llama-index llama-index-llms-huggingface ipywidgets\n",
    "!pip install transformers -U\n",
    "!pip install sentence_transformers\n",
    "!pip install unstructured\n",
    "!pip install pdfminer\n",
    "!pip install pypdf PyPDFLoader\n",
    "!pip install rapidocr-onnxruntime\n",
    "!pip install langchain_chroma\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a723b2-ff09-4650-a7db-e605eb20389d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-22T05:48:00.856127Z",
     "iopub.status.busy": "2024-06-22T05:48:00.855615Z",
     "iopub.status.idle": "2024-06-22T05:48:02.550483Z",
     "shell.execute_reply": "2024-06-22T05:48:02.548378Z",
     "shell.execute_reply.started": "2024-06-22T05:48:00.856093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = PyPDFLoader(\"../soybean_konw.pdf\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents[:])\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893d222f-855f-4e44-898b-37a1a7c3b3ab",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-22T05:48:04.781151Z",
     "iopub.status.busy": "2024-06-22T05:48:04.780529Z",
     "iopub.status.idle": "2024-06-22T05:48:05.050772Z",
     "shell.execute_reply": "2024-06-22T05:48:05.050096Z",
     "shell.execute_reply.started": "2024-06-22T05:48:04.781116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context'] template='Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge.\\ngenerate only questions based on the below query.\\nYou are a university professor. Your task is to set only 1 question for the upcoming Chinese quiz.\\nQuestions throughout the test should be diverse.\\nQuestions must be written in Chinese. The expression must be concise and clear.\\nIt should not exceed 20 Chinese characters. Words such as \"这\", \"那\", \"根据\", \"依据\" and other punctuation marks\\nshould not be used. Abbreviations may be used for titles and professional terms.\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "qa_generate_prompt_tmpl = \"\"\"\\\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "You are a university professor. Your task is to set only 1 question for the upcoming Chinese quiz.\n",
    "Questions throughout the test should be diverse.\n",
    "Questions must be written in Chinese. The expression must be concise and clear.\n",
    "It should not exceed 20 Chinese characters. Words such as \"这\", \"那\", \"根据\", \"依据\" and other punctuation marks\n",
    "should not be used. Abbreviations may be used for titles and professional terms.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=qa_generate_prompt_tmpl, \n",
    "    input_variables=[\"context\"]\n",
    "  )\n",
    "\n",
    "print(prompt)\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model=\"glm-4-0520\",\n",
    "    openai_api_key=\"661a7aa0aeb8ca129eb4647461123230.bl9w581QKpnMfBvs\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fc4061-1b4d-4195-bb7a-8fb2cf4e550a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-22T05:48:13.566286Z",
     "iopub.status.busy": "2024-06-22T05:48:13.565763Z",
     "iopub.status.idle": "2024-06-22T05:48:13.570634Z",
     "shell.execute_reply": "2024-06-22T05:48:13.569882Z",
     "shell.execute_reply.started": "2024-06-22T05:48:13.566249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = [texts[i].page_content for i in range(len(texts))]\n",
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8927b5-19c1-47d2-aa78-64b9fb07cd28",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-22T05:48:58.103646Z",
     "iopub.status.busy": "2024-06-22T05:48:58.102977Z",
     "iopub.status.idle": "2024-06-22T05:49:04.464065Z",
     "shell.execute_reply": "2024-06-22T05:49:04.463090Z",
     "shell.execute_reply.started": "2024-06-22T05:48:58.103610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_list = rag_chain.batch(content)\n",
    "# question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506c891-6346-436e-bebb-aa2b4f998cbf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 示例字典\n",
    "data_dict = {\n",
    "    'id': range(len(texts)),\n",
    "    'question': question_list,\n",
    "    'context': content\n",
    "}\n",
    "\n",
    "# 将字典转换为Pandas DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# 打印DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360f1179-efd5-4aeb-89ba-c1b43a585943",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-22T05:49:12.261348Z",
     "iopub.status.busy": "2024-06-22T05:49:12.260835Z",
     "iopub.status.idle": "2024-06-22T05:49:12.296449Z",
     "shell.execute_reply": "2024-06-22T05:49:12.295584Z",
     "shell.execute_reply.started": "2024-06-22T05:49:12.261315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_excel('soybean_question2.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
